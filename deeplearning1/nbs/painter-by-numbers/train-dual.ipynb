{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import ronan\n",
    "import chainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ronan:building labeled pairs dataset\n",
      "DEBUG:ronan:labeled pairs dataset: len 1000544\n",
      "DEBUG:ronan:building train, validation split\n",
      "DEBUG:ronan:building unlabeled image pair dataset\n",
      "DEBUG:ronan:done building dataset\n",
      "DEBUG:ronan:building labeled pairs dataset\n",
      "DEBUG:ronan:labeled pairs dataset: len 2084\n",
      "DEBUG:ronan:building train, validation split\n",
      "DEBUG:ronan:building unlabeled image pair dataset\n",
      "DEBUG:ronan:done building dataset\n"
     ]
    }
   ],
   "source": [
    "data_1M = ronan.load_painting_datasets(assemble_images=ronan.image_pair, size=1000000)\n",
    "data_1k = ronan.load_painting_datasets(assemble_images=ronan.image_pair, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ronan:building labeled pairs dataset\n",
      "DEBUG:ronan:labeled pairs dataset: len 2084\n",
      "DEBUG:ronan:building train, validation split\n",
      "DEBUG:ronan:building unlabeled image pair dataset\n",
      "DEBUG:ronan:done building dataset\n",
      "DEBUG:ronan:setting up optimizer\n",
      "DEBUG:ronan:creating trainer\n",
      "INFO:ronan:full model name: DualNet-1k-batch128\n",
      "DEBUG:ronan:running training loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time  epoch       iteration   main/accuracy  validation/main/accuracy  main/loss   validation/main/loss\n",
      "\u001b[J5.61051       0           1           0.335938                                 1.07063                           \n",
      "\u001b[J7.65204       0           2           0.8125                                   0.582695                          \n",
      "\u001b[J9.65802       0           3           0.6875                                   1.33569                           \n",
      "\u001b[J22.0935       0           4           0.71875        0.798828                  1.21723     0.641329              \n",
      "\u001b[J30.2947       0           5           0.796875                                 0.680959                          \n",
      "\u001b[J32.2892       0           6           0.734375                                 0.669274                          \n",
      "\u001b[J34.2819       0           7           0.484375                                 0.769993                          \n",
      "\u001b[J37.7676       0           8           0.382812       0.508772                  0.929379    0.851198              \n",
      "\u001b[J39.7473       0           9           0.484375                                 0.798523                          \n",
      "\u001b[J41.7359       0           10          0.625                                    0.6955                            \n",
      "\u001b[J43.7309       0           11          0.796875                                 0.594866                          \n",
      "\u001b[J54.5834       1           12          0.679688       0.796875                  0.837811    0.609834              \n",
      "\u001b[J62.8007       1           13          0.726562                                 0.793918                          \n",
      "\u001b[J64.8192       1           14          0.773438                                 0.656972                          \n",
      "\u001b[J66.8256       1           15          0.734375                                 0.664603                          \n",
      "\u001b[J70.3498       1           16          0.773438       0.692982                  0.4923      0.571461              \n",
      "\u001b[J78.3704       1           17          0.664062                                 0.618416                          \n",
      "\u001b[J80.3757       1           18          0.640625                                 0.651931                          \n",
      "\u001b[J82.3791       1           19          0.617188                                 0.64023                           \n",
      "\u001b[J93.1186       1           20          0.648438       0.691406                  0.637477    0.57504               \n",
      "\u001b[J95.12         1           21          0.679688                                 0.576738                          \n",
      "\u001b[J97.1182       1           22          0.726562                                 0.65232                           \n",
      "\u001b[J99.1212       2           23          0.835938                                 0.455237                          \n",
      "\u001b[J102.668       2           24          0.726562       0.736842                  0.711765    0.58525               \n",
      "\u001b[J104.667       2           25          0.8125                                   0.473207                          \n",
      "\u001b[J106.677       2           26          0.789062                                 0.508547                          \n",
      "\u001b[J108.733       2           27          0.742188                                 0.538516                          \n",
      "\u001b[J119.68        2           28          0.796875       0.740234                  0.470063    0.541533              \n",
      "\u001b[J128.069       2           29          0.703125                                 0.583808                          \n",
      "\u001b[J130.076       2           30          0.734375                                 0.573633                          \n",
      "\u001b[J132.092       2           31          0.65625                                  0.583389                          \n",
      "\u001b[J135.638       2           32          0.796875       0.675439                  0.483672    0.590014              \n",
      "\u001b[J137.685       2           33          0.78125                                  0.498704                          \n",
      "\u001b[J139.733       2           34          0.71875                                  0.56031                           \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-42903d137938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mronan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDualNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ronan.train(net, data, '1k',\n\u001b[0;32m----> 5\u001b[0;31m             train_batch_size=128, trigger_save_trainer=(500, 'iteration'))\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/projects/fastai/courses/deeplearning1/nbs/ronan.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(predictor, data, name, train_batch_size, validation_batch_size, trigger_save_trainer, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'running training loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_dog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/training/trainer.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, show_loop_exception_msg)\u001b[0m\n\u001b[1;32m    300\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                             \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshow_loop_exception_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/training/extensions/evaluator.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mreporter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mconfiguration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musing_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mreporter_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/projects/fastai/courses/deeplearning1/nbs/ronan.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/iterators/multiprocess_iterator.pyc\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmeasure_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefetch_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_comm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         (self.current_position, self.epoch, self.is_new_epoch,\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/iterators/multiprocess_iterator.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_queue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_not_empty_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_response_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefetch_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_not_full_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                     \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0m_sleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgotit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = ronan.load_painting_datasets(assemble_images=ronan.image_pair, size=1000)\n",
    "base = ronan.ResNet50Features()\n",
    "net = ronan.DualNet(base, output_size=2)\n",
    "ronan.train(net, data, '1k',\n",
    "            train_batch_size=128, trigger_save_trainer=(500, 'iteration'))\n",
    "# data_1k is buggy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ronan:building labeled pairs dataset\n",
      "DEBUG:ronan:labeled pairs dataset: len 1000544\n",
      "DEBUG:ronan:building train, validation split\n",
      "DEBUG:ronan:building unlabeled image pair dataset\n",
      "DEBUG:ronan:done building dataset\n",
      "DEBUG:ronan:setting up optimizer\n",
      "DEBUG:ronan:creating trainer\n",
      "INFO:ronan:full model name: DualNet-1M-batch128\n",
      "DEBUG:ronan:running training loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time  epoch       iteration   main/accuracy  validation/main/accuracy  main/loss   validation/main/loss\n",
      "\u001b[J3.16519       0           1           0.59375                                  0.739415                          \n",
      "\u001b[J5.18696       0           2           0.53125                                  0.910264                          \n",
      "\u001b[J7.20506       0           3           0.5625                                   0.826962                          \n",
      "\u001b[J19.3699       0           4           0.53125        0.542969                  0.850047    0.759761              \n",
      "\u001b[J27.6097       0           5           0.546875                                 0.748982                          \n",
      "\u001b[J29.628        0           6           0.539062                                 0.806558                          \n",
      "\u001b[J31.6548       0           7           0.523438                                 0.952728                          \n",
      "\u001b[J40.4796       0           8           0.539062       0.515625                  0.791282    0.820022              \n",
      "\u001b[J42.4986       0           9           0.515625                                 0.822172                          \n",
      "\u001b[J44.5293       0           10          0.5                                      0.927839                          \n",
      "\u001b[J46.5486       0           11          0.53125                                  0.813474                          \n",
      "\u001b[J55.3817       0           12          0.609375       0.582031                  0.684016    0.769771              \n",
      "\u001b[J57.4085       0           13          0.5625                                   0.781163                          \n",
      "\u001b[J59.4358       0           14          0.539062                                 0.900045                          \n",
      "\u001b[J61.4717       0           15          0.515625                                 0.839898                          \n",
      "\u001b[J70.3901       0           16          0.539062       0.542969                  0.777466    0.760903              \n",
      "\u001b[J72.4208       0           17          0.554688                                 0.75291                           \n",
      "\u001b[J74.4582       0           18          0.5                                      0.800297                          \n",
      "\u001b[J76.4887       0           19          0.570312                                 0.749918                          \n",
      "\u001b[J85.3771       0           20          0.546875       0.59375                   0.75472     0.695666              \n",
      "\u001b[J93.5328       0           21          0.671875                                 0.623312                          \n",
      "\u001b[J95.5719       0           22          0.546875                                 0.778342                          \n",
      "\u001b[J97.6064       0           23          0.515625                                 0.759109                          \n",
      "\u001b[J106.521       0           24          0.554688       0.542969                  0.718674    0.772231              \n",
      "\u001b[J108.544       0           25          0.554688                                 0.700351                          \n",
      "\u001b[J110.596       0           26          0.484375                                 0.853638                          \n",
      "\u001b[J112.633       0           27          0.554688                                 0.783776                          \n",
      "\u001b[J121.558       0           28          0.546875       0.552734                  0.726386    0.731582              \n",
      "\u001b[J123.597       0           29          0.507812                                 0.740443                          \n",
      "\u001b[J125.633       0           30          0.507812                                 0.775315                          \n",
      "\u001b[J127.677       0           31          0.445312                                 0.805095                          \n",
      "\u001b[J136.608       0           32          0.53125        0.558594                  0.751543    0.716519              \n",
      "\u001b[J138.649       0           33          0.484375                                 0.789466                          \n",
      "\u001b[J140.687       0           34          0.609375                                 0.715287                          \n",
      "\u001b[J142.728       0           35          0.570312                                 0.749985                          \n",
      "\u001b[J151.683       0           36          0.609375       0.548828                  0.722852    0.737397              \n",
      "\u001b[J153.727       0           37          0.570312                                 0.732621                          \n",
      "\u001b[J155.77        0           38          0.507812                                 0.733253                          \n",
      "\u001b[J157.829       0           39          0.515625                                 0.780732                          \n",
      "\u001b[J166.731       0           40          0.523438       0.554688                  0.793495    0.718172              \n",
      "\u001b[J168.769       0           41          0.539062                                 0.773878                          \n",
      "\u001b[J170.808       0           42          0.539062                                 0.715374                          \n",
      "\u001b[J172.85        0           43          0.648438                                 0.647811                          \n",
      "\u001b[J181.756       0           44          0.523438       0.535156                  0.719677    0.771991              \n",
      "\u001b[J183.804       0           45          0.546875                                 0.715099                          \n",
      "\u001b[J185.849       0           46          0.523438                                 0.77868                           \n",
      "\u001b[J187.884       0           47          0.546875                                 0.705157                          \n",
      "\u001b[J196.796       0           48          0.601562       0.564453                  0.700251    0.750709              \n",
      "\u001b[J198.837       0           49          0.578125                                 0.714601                          \n",
      "\u001b[J200.878       0           50          0.5                                      0.793967                          \n",
      "\u001b[J202.913       0           51          0.554688                                 0.713659                          \n",
      "\u001b[J211.849       0           52          0.5            0.541016                  0.763556    0.731655              \n",
      "\u001b[J213.879       0           53          0.554688                                 0.713623                          \n",
      "\u001b[J215.906       0           54          0.515625                                 0.746842                          \n",
      "\u001b[J217.953       0           55          0.59375                                  0.725006                          \n",
      "\u001b[J226.898       0           56          0.570312       0.568359                  0.74884     0.731573              \n",
      "\u001b[J228.944       0           57          0.53125                                  0.794642                          \n",
      "\u001b[J231           0           58          0.632812                                 0.681883                          \n",
      "\u001b[J233.035       0           59          0.539062                                 0.698517                          \n",
      "\u001b[J241.943       0           60          0.445312       0.521484                  0.795684    0.738549              \n",
      "\u001b[J243.976       0           61          0.570312                                 0.719585                          \n",
      "\u001b[J246.018       0           62          0.539062                                 0.719621                          \n",
      "\u001b[J248.062       0           63          0.5625                                   0.74441                           \n",
      "\u001b[J256.98        0           64          0.5625         0.599609                  0.700784    0.703824              \n",
      "\u001b[J259.038       0           65          0.570312                                 0.721545                          \n",
      "\u001b[J261.082       0           66          0.609375                                 0.677193                          \n",
      "\u001b[J263.12        0           67          0.53125                                  0.789481                          \n",
      "\u001b[J272.035       0           68          0.507812       0.576172                  0.774873    0.699687              \n",
      "\u001b[J274.079       0           69          0.5625                                   0.666972                          \n",
      "\u001b[J276.127       0           70          0.601562                                 0.693357                          \n",
      "\u001b[J278.175       0           71          0.617188                                 0.678825                          \n",
      "\u001b[J287.089       0           72          0.5625         0.552734                  0.734105    0.721258              \n",
      "\u001b[J289.148       0           73          0.570312                                 0.720488                          \n",
      "\u001b[J291.192       0           74          0.546875                                 0.730029                          \n",
      "\u001b[J293.224       0           75          0.625                                    0.710586                          \n",
      "\u001b[J302.127       0           76          0.59375        0.554688                  0.721056    0.723045              \n",
      "\u001b[J304.167       0           77          0.679688                                 0.633043                          \n",
      "\u001b[J306.201       0           78          0.515625                                 0.727065                          \n",
      "\u001b[J308.235       0           79          0.578125                                 0.723726                          \n",
      "\u001b[J317.173       0           80          0.632812       0.585938                  0.639641    0.686067              \n",
      "\u001b[J325.334       0           81          0.609375                                 0.683682                          \n",
      "\u001b[J327.384       0           82          0.546875                                 0.75085                           \n",
      "\u001b[J329.448       0           83          0.570312                                 0.685223                          \n",
      "\u001b[J338.343       0           84          0.539062       0.574219                  0.737817    0.713036              \n",
      "\u001b[J340.389       0           85          0.570312                                 0.699292                          \n",
      "\u001b[J342.435       0           86          0.5                                      0.735044                          \n",
      "\u001b[J344.466       0           87          0.601562                                 0.643356                          \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9c47215f6058>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mronan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDualNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ronan.train(net, data, '1M',\n\u001b[0;32m----> 5\u001b[0;31m             train_batch_size=128, trigger_save_trainer=(500, 'iteration'))\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/projects/fastai/courses/deeplearning1/nbs/ronan.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(predictor, data, name, train_batch_size, validation_batch_size, trigger_save_trainer, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'running training loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/training/trainer.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, show_loop_exception_msg)\u001b[0m\n\u001b[1;32m    300\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                             \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshow_loop_exception_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/training/extensions/log_report.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mstats_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mstats_cpu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# copy to CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mupdater\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdater\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base = ronan.ResNet50Features()\n",
    "net = ronan.DualNet(base, output_size=2)\n",
    "ronan.train(net, data_1M, '1M',\n",
    "            train_batch_size=128, trigger_save_trainer=(500, 'iteration'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ronan:building labeled pairs dataset\n",
      "DEBUG:ronan:labeled pairs dataset: len 1000544\n",
      "DEBUG:ronan:building train, validation split\n",
      "DEBUG:ronan:building unlabeled image pair dataset\n",
      "DEBUG:ronan:done building dataset\n",
      "DEBUG:ronan:setting up optimizer\n",
      "DEBUG:ronan:creating trainer\n",
      "INFO:ronan:full model name: DualNet-1M-ores2-batch128\n",
      "DEBUG:ronan:running training loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time  epoch       iteration   main/accuracy  validation/main/accuracy  main/loss   validation/main/loss\n",
      "\u001b[J3.05843       0           1           0.507812                                 1.79602                           \n",
      "\u001b[J7.17186       0           2           0.507812       0.496094                  1483.42     1354.98               \n",
      "\u001b[J15.4369       0           3           0.515625                                 1298.06                           \n",
      "\u001b[J18.1484       0           4           0.46875        0.472656                  722.833     250.999               \n",
      "\u001b[J26.169        0           5           0.460938                                 269.726                           \n",
      "\u001b[J28.8797       0           6           0.484375       0.496094                  559.996     439.634               \n",
      "\u001b[J29.9676       0           7           0.515625                                 435.833                           \n",
      "\u001b[J32.6753       0           8           0.453125       0.464844                  106.751     500.478               \n",
      "\u001b[J33.7508       0           9           0.554688                                 412.97                            \n",
      "\u001b[J36.4597       0           10          0.5625         0.542969                  634.201     677.555               \n",
      "\u001b[J37.5319       0           11          0.4375                                   841.355                           \n",
      "\u001b[J40.2255       0           12          0.515625       0.523438                  497.018     109.096               \n",
      "\u001b[J48.0398       0           13          0.570312                                 97.9367                           \n",
      "\u001b[J50.7519       0           14          0.515625       0.480469                  387.687     691.7                 \n",
      "\u001b[J51.8288       0           15          0.578125                                 558.614                           \n",
      "\u001b[J54.5305       0           16          0.429688       0.488281                  849.092     617.57                \n",
      "\u001b[J55.6463       0           17          0.476562                                 646.653                           \n",
      "\u001b[J58.3486       0           18          0.515625       0.5625                    287.086     126.314               \n",
      "\u001b[J59.4249       0           19          0.53125                                  130.025                           \n",
      "\u001b[J62.1398       0           20          0.460938       0.453125                  389.872     400.09                \n",
      "\u001b[J63.2345       0           21          0.523438                                 353.967                           \n",
      "\u001b[J65.9596       0           22          0.515625       0.546875                  218.146     59.5958               \n",
      "\u001b[J73.8995       0           23          0.523438                                 68.0347                           \n",
      "\u001b[J76.6214       0           24          0.515625       0.496094                  188.269     167.325               \n",
      "\u001b[J77.6913       0           25          0.554688                                 157.028                           \n",
      "\u001b[J80.3968       0           26          0.515625       0.519531                  75.7562     133.171               \n",
      "\u001b[J81.483        0           27          0.539062                                 135.806                           \n",
      "\u001b[J84.2053       0           28          0.484375       0.550781                  156.871     52.1152               \n",
      "\u001b[J92.0302       0           29          0.507812                                 59.7608                           \n",
      "\u001b[J94.7541       0           30          0.476562       0.457031                  131.697     116.4                 \n",
      "\u001b[J95.8448       0           31          0.484375                                 116.333                           \n",
      "\u001b[J98.5693       0           32          0.53125        0.496094                  65.7379     142.755               \n",
      "\u001b[J99.6515       0           33          0.554688                                 124.557                           \n",
      "\u001b[J102.366       0           34          0.515625       0.570312                  95.0812     57.879                \n",
      "\u001b[J103.451       0           35          0.523438                                 78.2211                           \n",
      "\u001b[J106.168       0           36          0.460938       0.554688                  103.211     40.127                \n",
      "\u001b[J113.986       0           37          0.570312                                 44.9423                           \n",
      "\u001b[J116.718       0           38          0.601562       0.589844                  73.2664     45.475                \n",
      "\u001b[J117.823       0           39          0.664062                                 42.352                            \n",
      "\u001b[J120.574       0           40          0.539062       0.546875                  52.3366     33.7792               \n",
      "\u001b[J128.501       0           41          0.492188                                 43.8832                           \n",
      "\u001b[J131.243       0           42          0.484375       0.515625                  120.491     86.3861               \n",
      "\u001b[J132.324       0           43          0.492188                                 88.1977                           \n",
      "\u001b[J135.045       0           44          0.59375        0.476562                  93.2828     164.806               \n",
      "\u001b[J136.124       0           45          0.53125                                  151.545                           \n",
      "\u001b[J138.827       0           46          0.484375       0.484375                  48.3613     217.197               \n",
      "\u001b[J139.912       0           47          0.5625                                   182.605                           \n",
      "\u001b[J142.63        0           48          0.570312       0.488281                  261.92      243.727               \n",
      "\u001b[J143.72        0           49          0.609375                                 184.553                           \n",
      "\u001b[J146.442       0           50          0.5            0.476562                  50.4361     288.461               \n",
      "\u001b[J147.538       0           51          0.46875                                  292.898                           \n",
      "\u001b[J150.267       0           52          0.4375         0.476562                  445.319     332.942               \n",
      "\u001b[J151.353       0           53          0.5                                      315.885                           \n",
      "\u001b[J154.066       0           54          0.515625       0.53125                   86.7164     249.627               \n",
      "\u001b[J155.15        0           55          0.460938                                 291.771                           \n",
      "\u001b[J157.87        0           56          0.46875        0.457031                  451.411     411.899               \n",
      "\u001b[J158.946       0           57          0.453125                                 417.634                           \n",
      "\u001b[J161.694       0           58          0.4375         0.476562                  189.967     197.969               \n",
      "\u001b[J162.781       0           59          0.585938                                 150.486                           \n",
      "\u001b[J165.509       0           60          0.570312       0.484375                  333.809     439.445               \n",
      "\u001b[J166.59        0           61          0.4375                                   495.47                            \n",
      "\u001b[J169.312       0           62          0.421875       0.558594                  346.334     31.0462               \n",
      "\u001b[J177.3         0           63          0.546875                                 31.4689                           \n",
      "\u001b[J180.046       0           64          0.492188       0.511719                  299.114     396.156               \n",
      "\u001b[J181.129       0           65          0.484375                                 420.992                           \n",
      "\u001b[J183.855       0           66          0.4375         0.558594                  378.63      82.0663               \n",
      "\u001b[J184.941       0           67          0.523438                                 91.2259                           \n",
      "\u001b[J187.661       0           68          0.453125       0.542969                  291.283     385.641               \n",
      "\u001b[J188.755       0           69          0.5                                      421.585                           \n",
      "\u001b[J191.493       0           70          0.507812       0.492188                  380.405     236.472               \n",
      "\u001b[J192.589       0           71          0.476562                                 246.129                           \n",
      "\u001b[J195.3         0           72          0.492188       0.566406                  86.4824     205.517               \n",
      "\u001b[J196.379       0           73          0.46875                                  269.999                           \n",
      "\u001b[J199.101       0           74          0.554688       0.574219                  208.987     90.6609               \n",
      "\u001b[J200.188       0           75          0.492188                                 90.2815                           \n",
      "\u001b[J202.914       0           76          0.5625         0.492188                  122.742     231.057               \n",
      "\u001b[J203.99        0           77          0.59375                                  186.266                           \n",
      "\u001b[J206.74        0           78          0.554688       0.535156                  159.065     53.6959               \n",
      "\u001b[J207.826       0           79          0.578125                                 47.0742                           \n",
      "\u001b[J210.547       0           80          0.523438       0.496094                  138.466     168.076               \n",
      "\u001b[J211.635       0           81          0.523438                                 153.139                           \n",
      "\u001b[J214.357       0           82          0.585938       0.546875                  49.7744     126.172               \n",
      "\u001b[J215.442       0           83          0.554688                                 132.485                           \n",
      "\u001b[J218.17        0           84          0.609375       0.46875                   145.145     98.1856               \n",
      "\u001b[J219.267       0           85          0.539062                                 85.7543                           \n",
      "\u001b[J221.988       0           86          0.59375        0.480469                  82.2786     148.859               \n",
      "\u001b[J223.075       0           87          0.523438                                 130.177                           \n",
      "\u001b[J225.824       0           88          0.625          0.503906                  63.2657     115.439               \n",
      "\u001b[J226.919       0           89          0.421875                                 141.224                           \n",
      "\u001b[J229.646       0           90          0.53125        0.566406                  94.9955     48.9706               \n",
      "\u001b[J230.738       0           91          0.5625                                   47.229                            \n",
      "\u001b[J233.495       0           92          0.5            0.570312                  112.732     51.0998               \n",
      "\u001b[J234.574       0           93          0.585938                                 54.6759                           \n",
      "\u001b[J237.301       0           94          0.523438       0.511719                  86.4117     94.27                 \n",
      "\u001b[J238.395       0           95          0.460938                                 108.105                           \n",
      "\u001b[J241.138       0           96          0.460938       0.5625                    79.8176     67.5884               \n",
      "\u001b[J242.219       0           97          0.46875                                  83.8019                           \n",
      "\u001b[J244.955       0           98          0.648438       0.558594                  40.6882     71.4938               \n",
      "\u001b[J246.059       0           99          0.390625                                 105.253                           \n",
      "\u001b[J248.81        0           100         0.484375       0.554688                  61.2327     45.3602               \n",
      "\u001b[J249.896       0           101         0.625                                    38.3724                           \n",
      "\u001b[J252.628       0           102         0.492188       0.609375                  65.0815     30.1158               \n",
      "\u001b[J260.525       0           103         0.570312                                 22.3188                           \n",
      "\u001b[J263.258       0           104         0.507812       0.519531                  103.467     64.8373               \n",
      "\u001b[J264.343       0           105         0.523438                                 61.2315                           \n",
      "\u001b[J267.08        0           106         0.523438       0.570312                  117.014     111.92                \n",
      "\u001b[J268.161       0           107         0.507812                                 142.818                           \n",
      "\u001b[J270.907       0           108         0.5625         0.535156                  24.7029     96.3978               \n",
      "\u001b[J271.988       0           109         0.523438                                 100.134                           \n",
      "\u001b[J274.708       0           110         0.5            0.507812                  45.6698     149.818               \n",
      "\u001b[J275.811       0           111         0.5                                      153.96                            \n",
      "\u001b[J278.539       0           112         0.53125        0.496094                  168.358     45.9583               \n",
      "\u001b[J279.622       0           113         0.53125                                  46.6611                           \n",
      "\u001b[J282.362       0           114         0.46875        0.492188                  218.414     276.64                \n",
      "\u001b[J283.45        0           115         0.507812                                 267.988                           \n",
      "\u001b[J286.172       0           116         0.539062       0.554688                  152.068     63.7929               \n",
      "\u001b[J287.289       0           117         0.429688                                 96.6383                           \n",
      "\u001b[J290.025       0           118         0.460938       0.566406                  133.768     31.8068               \n",
      "\u001b[J291.11        0           119         0.609375                                 23.8141                           \n",
      "\u001b[J293.84        0           120         0.5            0.578125                  93.9672     25.6095               \n",
      "\u001b[J301.61        0           121         0.546875                                 29.8301                           \n",
      "\u001b[J304.326       0           122         0.515625       0.550781                  67.6237     27.0765               \n",
      "\u001b[J305.422       0           123         0.617188                                 26.8395                           \n",
      "\u001b[J308.145       0           124         0.546875       0.578125                  39.6175     33.0137               \n",
      "\u001b[J309.223       0           125         0.578125                                 27.0157                           \n",
      "\u001b[J311.961       0           126         0.578125       0.492188                  18.1806     96.7372               \n",
      "\u001b[J313.059       0           127         0.492188                                 92.2288                           \n",
      "\u001b[J315.798       0           128         0.523438       0.511719                  29.7064     129.3                 \n",
      "\u001b[J316.872       0           129         0.484375                                 132.722                           \n",
      "\u001b[J319.619       0           130         0.515625       0.535156                  109.219     71.6451               \n",
      "\u001b[J320.717       0           131         0.515625                                 70.142                            \n",
      "\u001b[J323.443       0           132         0.492188       0.527344                  87.4061     71.8185               \n",
      "\u001b[J324.545       0           133         0.492188                                 73.1403                           \n",
      "\u001b[J327.285       0           134         0.515625       0.488281                  56.1934     116.254               \n",
      "\u001b[J328.372       0           135         0.460938                                 116.481                           \n",
      "\u001b[J331.108       0           136         0.507812       0.523438                  83.9191     87.1048               \n",
      "\u001b[J332.188       0           137         0.460938                                 95.2798                           \n",
      "\u001b[J334.921       0           138         0.46875        0.457031                  83.7544     86.9952               \n",
      "\u001b[J336.015       0           139         0.414062                                 99.0504                           \n",
      "\u001b[J338.745       0           140         0.601562       0.496094                  37.9067     89.628                \n",
      "\u001b[J339.84        0           141         0.453125                                 98.6825                           \n",
      "\u001b[J342.576       0           142         0.523438       0.480469                  40.7017     129.82                \n",
      "\u001b[J343.673       0           143         0.507812                                 117.871                           \n",
      "\u001b[J346.426       0           144         0.492188       0.515625                  117.282     43.8349               \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6ff1037935e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             trigger_save_trainer=(500, 'iteration'))\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/projects/fastai/courses/deeplearning1/nbs/ronan.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(predictor, data, name, train_batch_size, validation_batch_size, trigger_save_trainer, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'running training loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/training/trainer.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, show_loop_exception_msg)\u001b[0m\n\u001b[1;32m    300\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                             \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshow_loop_exception_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/training/extensions/log_report.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mstats_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mstats_cpu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# copy to CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mupdater\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdater\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = ronan.load_painting_datasets(assemble_images=ronan.image_pair, size=1000000)\n",
    "#with chainer.using_config('debug', True):\n",
    "base = ronan.ResNet50Features(output_layer='res2')\n",
    "net = ronan.DualNet(base, output_size=2)\n",
    "ronan.train(net, data, '1M-ores2',\n",
    "            train_batch_size=128,\n",
    "            validation_batch_size=256,\n",
    "            trigger_save_trainer=(500, 'iteration'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ronan:building labeled pairs dataset\n",
      "DEBUG:ronan:labeled pairs dataset: len 1000544\n",
      "DEBUG:ronan:building train, validation split\n",
      "DEBUG:ronan:building unlabeled image pair dataset\n",
      "DEBUG:ronan:done building dataset\n",
      "DEBUG:ronan:setting up optimizer\n",
      "DEBUG:ronan:creating trainer\n",
      "INFO:ronan:full model name: DualNet-1M-ores2-fres3-batch128\n",
      "DEBUG:ronan:running training loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time  epoch       iteration   main/accuracy  validation/main/accuracy  main/loss   validation/main/loss\n",
      "\u001b[J3.2397        0           1           0.515625                                 1.08642                           \n",
      "\u001b[J7.95117       0           2           0.429688       0.503906                  726.447     339.108               \n",
      "\u001b[J16.9362       0           3           0.570312                                 281.109                           \n",
      "\u001b[J21.4063       0           4           0.40625        0.527344                  71.0799     116.252               \n",
      "\u001b[J30.1515       0           5           0.492188                                 98.3925                           \n",
      "\u001b[J34.6173       0           6           0.5            0.492188                  15.5891     21.2384               \n",
      "\u001b[J43.2768       0           7           0.53125                                  9.02295                           \n",
      "\u001b[J47.7496       0           8           0.40625        0.472656                  62.1313     11.8024               \n",
      "\u001b[J56.4757       0           9           0.507812                                 8.52719                           \n",
      "\u001b[J60.9492       0           10          0.492188       0.480469                  61.8601     30.3378               \n",
      "\u001b[J63.2565       0           11          0.476562                                 44.7155                           \n",
      "\u001b[J67.7314       0           12          0.40625        0.515625                  38.576      181.588               \n",
      "\u001b[J70.0529       0           13          0.460938                                 29.9408                           \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-14a087ca2d40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             trigger_save_trainer=(500, 'iteration'))\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/projects/fastai/courses/deeplearning1/nbs/ronan.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(predictor, data, name, train_batch_size, validation_batch_size, trigger_save_trainer, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'running training loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/training/trainer.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, show_loop_exception_msg)\u001b[0m\n\u001b[1;32m    300\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                             \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshow_loop_exception_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/training/extensions/log_report.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mstats_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mstats_cpu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# copy to CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mupdater\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdater\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = ronan.load_painting_datasets(assemble_images=ronan.image_pair, size=1000000)\n",
    "#with chainer.using_config('debug', True):\n",
    "base = ronan.ResNet50Features(output_layer='res3', finetune_from_layer='res3')\n",
    "net = ronan.DualNet(base, output_size=2)\n",
    "ronan.train(net, data, '1M-ores2-fres3',\n",
    "            train_batch_size=128,\n",
    "            validation_batch_size=256,\n",
    "            trigger_save_trainer=(500, 'iteration'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ronan:building labeled pairs dataset\n",
      "DEBUG:ronan:labeled pairs dataset: len 1000544\n",
      "DEBUG:ronan:building train, validation split\n",
      "DEBUG:ronan:building unlabeled image pair dataset\n",
      "DEBUG:ronan:done building dataset\n",
      "DEBUG:ronan:setting up optimizer\n",
      "DEBUG:ronan:creating trainer\n",
      "INFO:ronan:full model name: DualNet-1M-ores5-fres5-batch128\n",
      "DEBUG:ronan:running training loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time  epoch       iteration   main/accuracy  validation/main/accuracy  main/loss   validation/main/loss\n",
      "\u001b[J3.67057       0           1           0.515625                                 0.772956                          \n",
      "\u001b[J9.77898       0           2           0.601562       0.515625                  0.841951    1.97126               \n",
      "\u001b[J18.766        0           3           0.570312                                 1.19079                           \n",
      "\u001b[J24.8857       0           4           0.578125       0.535156                  1.04859     1.15652               \n",
      "\u001b[J33.6954       0           5           0.445312                                 1.18502                           \n",
      "\u001b[J39.8179       0           6           0.53125        0.546875                  0.937193    1.03222               \n",
      "\u001b[J48.6435       0           7           0.625                                    0.837763                          \n",
      "\u001b[J54.8008       0           8           0.554688       0.503906                  0.888777    1.50499               \n",
      "\u001b[J57.5431       0           9           0.53125                                  0.905203                          \n",
      "\u001b[J63.7118       0           10          0.59375        0.535156                  0.725774    1.64322               \n",
      "\u001b[J66.463        0           11          0.523438                                 0.823159                          \n",
      "\u001b[J72.6211       0           12          0.609375       0.515625                  0.875723    1.00703               \n",
      "\u001b[J81.5668       0           13          0.5625                                   0.731212                          \n",
      "\u001b[J87.7246       0           14          0.515625       0.46875                   0.751639    1.20168               \n",
      "\u001b[J90.4858       0           15          0.5                                      0.80189                           \n",
      "\u001b[J96.663        0           16          0.492188       0.546875                  0.808833    1.01975               \n",
      "\u001b[J99.4234       0           17          0.5625                                   0.704616                          \n",
      "\u001b[J105.601       0           18          0.515625       0.554688                  0.763454    0.898604              \n",
      "\u001b[J114.444       0           19          0.640625                                 0.728221                          \n",
      "\u001b[J120.63        0           20          0.554688       0.535156                  0.836859    0.881253              \n",
      "\u001b[J129.519       0           21          0.507812                                 0.774382                          \n",
      "\u001b[J135.707       0           22          0.492188       0.597656                  0.794511    0.756678              \n",
      "\u001b[J144.505       0           23          0.570312                                 0.701922                          \n",
      "\u001b[J150.68        0           24          0.585938       0.59375                   0.677099    0.724556              \n",
      "\u001b[J159.464       0           25          0.539062                                 0.72915                           \n",
      "\u001b[J165.648       0           26          0.570312       0.578125                  0.688353    0.701084              \n",
      "\u001b[J174.554       0           27          0.632812                                 0.67109                           \n",
      "\u001b[J180.711       0           28          0.46875        0.601562                  0.744226    0.696417              \n",
      "\u001b[J189.534       0           29          0.609375                                 0.650386                          \n",
      "\u001b[J195.716       0           30          0.546875       0.601562                  0.663035    0.676427              \n",
      "\u001b[J204.587       0           31          0.617188                                 0.699007                          \n",
      "\u001b[J210.727       0           32          0.554688       0.554688                  0.693841    0.731362              \n",
      "\u001b[J213.529       0           33          0.546875                                 0.65358                           \n",
      "\u001b[J219.698       0           34          0.59375        0.625                     0.744141    0.657324              \n",
      "\u001b[J228.689       0           35          0.539062                                 0.708459                          \n",
      "\u001b[J234.882       0           36          0.5625         0.585938                  0.717404    0.688048              \n",
      "\u001b[J237.65        0           37          0.570312                                 0.656749                          \n",
      "\u001b[J243.831       0           38          0.640625       0.597656                  0.655096    0.747119              \n",
      "\u001b[J246.596       0           39          0.59375                                  0.685131                          \n",
      "\u001b[J252.8         0           40          0.523438       0.589844                  0.721128    0.741911              \n",
      "\u001b[J255.576       0           41          0.570312                                 0.693541                          \n",
      "\u001b[J261.754       0           42          0.625          0.539062                  0.645915    0.73116               \n",
      "\u001b[J264.544       0           43          0.625                                    0.652027                          \n",
      "\u001b[J270.763       0           44          0.59375        0.578125                  0.647224    0.682007              \n",
      "\u001b[J273.532       0           45          0.484375                                 0.722157                          \n",
      "\u001b[J279.713       0           46          0.578125       0.601562                  0.716398    0.691861              \n",
      "\u001b[J282.474       0           47          0.726562                                 0.590515                          \n",
      "\u001b[J288.681       0           48          0.53125        0.589844                  0.738624    0.67504               \n",
      "\u001b[J291.451       0           49          0.640625                                 0.6369                            \n",
      "\u001b[J297.646       0           50          0.625          0.578125                  0.612828    0.688161              \n",
      "\u001b[J300.4         0           51          0.632812                                 0.636658                          \n",
      "\u001b[J306.594       0           52          0.570312       0.523438                  0.692847    0.752982              \n",
      "\u001b[J309.344       0           53          0.578125                                 0.734436                          \n",
      "\u001b[J315.521       0           54          0.640625       0.617188                  0.650098    0.681029              \n",
      "\u001b[J318.278       0           55          0.625                                    0.626793                          \n",
      "\u001b[J324.451       0           56          0.617188       0.578125                  0.696013    0.678678              \n",
      "\u001b[J327.208       0           57          0.5625                                   0.659547                          \n",
      "\u001b[J333.379       0           58          0.585938       0.527344                  0.65579     0.711079              \n",
      "\u001b[J336.162       0           59          0.570312                                 0.674977                          \n",
      "\u001b[J342.396       0           60          0.507812       0.582031                  0.74516     0.709511              \n",
      "\u001b[J345.161       0           61          0.539062                                 0.722899                          \n",
      "\u001b[J351.328       0           62          0.53125        0.601562                  0.665927    0.673556              \n",
      "\u001b[J354.111       0           63          0.585938                                 0.68674                           \n",
      "\u001b[J360.263       0           64          0.632812       0.539062                  0.641791    0.706251              \n",
      "\u001b[J363.016       0           65          0.578125                                 0.675818                          \n",
      "\u001b[J369.22        0           66          0.617188       0.609375                  0.653336    0.659911              \n",
      "\u001b[J372.018       0           67          0.554688                                 0.704292                          \n",
      "\u001b[J378.201       0           68          0.539062       0.601562                  0.713805    0.681091              \n",
      "\u001b[J380.975       0           69          0.617188                                 0.6631                            \n",
      "\u001b[J387.18        0           70          0.523438       0.582031                  0.705204    0.652153              \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c58889625ec4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             trigger_save_trainer=(500, 'iteration'))\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/projects/fastai/courses/deeplearning1/nbs/ronan.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(predictor, data, name, train_batch_size, validation_batch_size, trigger_save_trainer, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'running training loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/training/trainer.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, show_loop_exception_msg)\u001b[0m\n\u001b[1;32m    300\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                             \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshow_loop_exception_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/training/extensions/_snapshot.pyc\u001b[0m in \u001b[0;36msnapshot_object\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriority\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msnapshot_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0m_snapshot_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavefun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msnapshot_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/training/extensions/_snapshot.pyc\u001b[0m in \u001b[0;36m_snapshot_object\u001b[0;34m(trainer, target, filename, savefun)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmppath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkstemp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0msavefun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmppath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/serializers/npz.pyc\u001b[0m in \u001b[0;36msave_npz\u001b[0;34m(filename, obj, compression)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez_compressed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#with chainer.using_config('debug', True):\n",
    "base = ronan.ResNet50Features(finetune_from_layer='res5')\n",
    "net = ronan.DualNet(base, output_size=2)\n",
    "ronan.train(net, data, '1M-ores5-fres5',\n",
    "            train_batch_size=128,\n",
    "            validation_batch_size=256,\n",
    "            trigger_save_trainer=(500, 'iteration'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ronan:setting up optimizer\n",
      "DEBUG:ronan:creating trainer\n",
      "INFO:ronan:full model name: DualNet-1k-ores5-batch128\n",
      "DEBUG:ronan:running training loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time  epoch       iteration   main/accuracy  validation/main/accuracy  main/loss   validation/main/loss\n",
      "\u001b[J2.936         0           1           0.679688                                 0.66694                           \n",
      "\u001b[J8.64778       0           2           0.6875         0.648438                  0.662984    0.683927              \n",
      "\u001b[J16.8723       0           3           0.546875                                 0.725904                          \n",
      "\u001b[J22.2946       0           4           0.6875         0.835938                  0.76169     0.459087              \n",
      "\u001b[J30.5008       0           5           0.757812                                 0.586101                          \n",
      "\u001b[J34.0482       0           6           0.703125       0.754386                  0.642697    0.552246              \n",
      "\u001b[J36.0642       0           7           0.695312                                 0.589235                          \n",
      "\u001b[J41.6686       0           8           0.757812       0.726562                  0.549953    0.594631              \n",
      "\u001b[J43.7433       0           9           0.695312                                 0.593474                          \n",
      "\u001b[J49.1661       0           10          0.726562       0.800781                  0.595883    0.473973              \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-142dd1f96b3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             trigger_save_trainer=(500, 'iteration'))\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/projects/fastai/courses/deeplearning1/nbs/ronan.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(predictor, data, name, train_batch_size, validation_batch_size, trigger_save_trainer, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'running training loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/training/trainer.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, show_loop_exception_msg)\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mreporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/training/updater.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \"\"\"\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/training/updater.pyc\u001b[0m in \u001b[0;36mupdate_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/optimizer.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, lossfun, *args, **kwds)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlossfun\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0muse_cleargrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_use_cleargrads'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muse_cleargrads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleargrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/links/model/classifier.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlossfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mreporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/projects/fastai/courses/deeplearning1/nbs/ronan.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mi2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         h = chainer.functions.concat((self.base(i1),\n\u001b[0m\u001b[1;32m    102\u001b[0m                                       self.base(i2)))\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_final\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/projects/fastai/courses/deeplearning1/nbs/ronan.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m         return call_finetune(x, self.resnet50,\n\u001b[1;32m     83\u001b[0m                              \u001b[0mbackprop_from_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinetune_from_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                              target_layer=self.output_layer)\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/projects/fastai/courses/deeplearning1/nbs/ronan.pyc\u001b[0m in \u001b[0;36mcall_finetune\u001b[0;34m(x, net, backprop_from_layer, target_layer)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmaybe_backprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget_layer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/links/model/vision/resnet.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/links/model/vision/resnet.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/functions/activation/relu.pyc\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \"\"\"\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/function_node.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_indexes_to_retain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_indexes_to_retain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/function_node.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/functions/activation/relu.pyc\u001b[0m in \u001b[0;36mforward_gpu\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/cupy/core/fusion.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cupy_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base = ronan.ResNet50Features()\n",
    "net = ronan.DualNet(base, output_size=2)\n",
    "ronan.train(net, data_1k, '1k-ores5',\n",
    "            train_batch_size=128,\n",
    "            validation_batch_size=256,\n",
    "            trigger_save_trainer=(500, 'iteration'))\n",
    "# data_1k is buggy! do not use! it has 3/4 same artist instead of 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ronan:setting up optimizer\n",
      "DEBUG:ronan:creating trainer\n",
      "INFO:ronan:full model name: DualNet-1M-ores2-batch128\n",
      "DEBUG:ronan:running training loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time  epoch       iteration   main/accuracy  validation/main/accuracy  main/loss   validation/main/loss\n",
      "\u001b[J1.99207       0           1           0.609375                                 0.771377                          \n",
      "\u001b[J5.93249       0           2           0.476562       0.496094                  1421.22     410.189               \n",
      "\u001b[J14.308        0           3           0.414062                                 478.192                           \n",
      "\u001b[J17.0347       0           4           0.484375       0.472656                  818.803     1173.59               \n",
      "\u001b[J18.1549       0           5           0.5625                                   990.107                           \n",
      "\u001b[J20.879        0           6           0.476562       0.5                       1096.52     641.768               \n",
      "\u001b[J21.9465       0           7           0.414062                                 775.525                           \n",
      "\u001b[J24.646        0           8           0.484375       0.464844                  24.0594     720.487               \n",
      "\u001b[J25.7284       0           9           0.453125                                 738.767                           \n",
      "\u001b[J28.4655       0           10          0.671875       0.542969                  633.287     950.736               \n",
      "\u001b[J29.5365       0           11          0.507812                                 1039.19                           \n",
      "\u001b[J32.2284       0           12          0.578125       0.523438                  741.304     523.553               \n",
      "\u001b[J33.3547       0           13          0.507812                                 539.112                           \n",
      "\u001b[J36.0423       0           14          0.515625       0.480469                  57.8134     566.247               \n",
      "\u001b[J37.1159       0           15          0.492188                                 568.857                           \n",
      "\u001b[J39.8187       0           16          0.460938       0.488281                  994.45      997.883               \n",
      "\u001b[J40.9031       0           17          0.414062                                 1122.53                           \n",
      "\u001b[J43.6124       0           18          0.546875       0.453125                  745.999     582.441               \n",
      "\u001b[J44.6932       0           19          0.382812                                 674.458                           \n",
      "\u001b[J47.3913       0           20          0.53125        0.453125                  70.4677     505.331               \n",
      "\u001b[J48.4638       0           21          0.484375                                 486.957                           \n",
      "\u001b[J51.1694       0           22          0.5            0.507812                  791.83      890.884               \n",
      "\u001b[J52.2459       0           23          0.492188                                 922.921                           \n",
      "\u001b[J54.9483       0           24          0.53125        0.5                       792.673     616.107               \n",
      "\u001b[J56.0601       0           25          0.546875                                 562.929                           \n",
      "\u001b[J58.833        0           26          0.59375        0.527344                  214.165     141.225               \n",
      "\u001b[J66.7358       0           27          0.46875                                  146.649                           \n",
      "\u001b[J69.473        0           28          0.515625       0.488281                  386.135     455.432               \n",
      "\u001b[J70.5962       0           29          0.539062                                 419.445                           \n",
      "\u001b[J73.3142       0           30          0.484375       0.472656                  359.398     121.843               \n",
      "\u001b[J81.2092       0           31          0.5                                      123.446                           \n",
      "\u001b[J83.9451       0           32          0.46875        0.46875                   238.627     380.897               \n",
      "\u001b[J85.0368       0           33          0.4375                                   418.141                           \n",
      "\u001b[J87.7525       0           34          0.523438       0.492188                  301.186     146.319               \n",
      "\u001b[J88.8465       0           35          0.484375                                 156.677                           \n",
      "\u001b[J91.5517       0           36          0.5625         0.492188                  136.869     333.604               \n",
      "\u001b[J92.6748       0           37          0.546875                                 305.192                           \n",
      "\u001b[J95.3831       0           38          0.515625       0.507812                  322.523     194.066               \n",
      "\u001b[J96.4592       0           39          0.460938                                 198.04                            \n",
      "\u001b[J99.1771       0           40          0.515625       0.519531                  106.104     250.158               \n",
      "\u001b[J100.273       0           41          0.539062                                 236.525                           \n",
      "\u001b[J102.982       0           42          0.570312       0.546875                  228.332     142.495               \n",
      "\u001b[J104.103       0           43          0.585938                                 128.099                           \n",
      "\u001b[J106.827       0           44          0.539062       0.484375                  91.9968     195.237               \n",
      "\u001b[J107.917       0           45          0.476562                                 233.514                           \n",
      "\u001b[J110.631       0           46          0.515625       0.554688                  155.487     69.7447               \n",
      "\u001b[J118.583       0           47          0.570312                                 70.2859                           \n",
      "\u001b[J121.313       0           48          0.53125        0.566406                  118.098     97.4477               \n",
      "\u001b[J122.392       0           49          0.585938                                 93.9433                           \n",
      "\u001b[J125.125       0           50          0.601562       0.5                       50.281      114.058               \n",
      "\u001b[J126.193       0           51          0.523438                                 111.424                           \n",
      "\u001b[J128.915       0           52          0.515625       0.527344                  100.971     69.2528               \n",
      "\u001b[J136.737       0           53          0.59375                                  60.051                            \n",
      "\u001b[J139.486       0           54          0.585938       0.59375                   105.657     65.5556               \n",
      "\u001b[J147.317       0           55          0.5625                                   77.013                            \n",
      "\u001b[J150.08        0           56          0.5625         0.53125                   70.458      95.1687               \n",
      "\u001b[J151.186       0           57          0.53125                                  100.409                           \n",
      "\u001b[J153.9         0           58          0.492188       0.535156                  43.0468     78.1594               \n",
      "\u001b[J154.971       0           59          0.460938                                 88.4852                           \n",
      "\u001b[J157.7         0           60          0.5625         0.515625                  32.0689     58.2035               \n",
      "\u001b[J165.706       0           61          0.523438                                 56.9762                           \n",
      "\u001b[J168.445       0           62          0.570312       0.539062                  35.1152     27.0317               \n",
      "\u001b[J176.292       0           63          0.59375                                  23.9249                           \n",
      "\u001b[J179.007       0           64          0.523438       0.519531                  44.4928     48.2138               \n",
      "\u001b[J180.113       0           65          0.476562                                 52.8033                           \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-058cc0cdb366>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             trigger_save_trainer=(500, 'iteration'))\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/projects/fastai/courses/deeplearning1/nbs/ronan.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(predictor, data, name, train_batch_size, validation_batch_size, trigger_save_trainer, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'running training loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/training/trainer.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, show_loop_exception_msg)\u001b[0m\n\u001b[1;32m    300\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                             \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshow_loop_exception_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/training/extensions/log_report.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mstats_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mstats_cpu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# copy to CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mupdater\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdater\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base = ronan.ResNet50Features(output_layer='res2')\n",
    "net = ronan.DualNet(base, output_size=2)\n",
    "ronan.train(net, data_1M, '1M-ores2',\n",
    "            train_batch_size=128,\n",
    "            validation_batch_size=256,\n",
    "            trigger_save_trainer=(500, 'iteration'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ronan:setting up optimizer\n",
      "DEBUG:ronan:creating trainer\n",
      "INFO:ronan:full model name: DualNet-1M-ores5-fres1-batch128\n",
      "DEBUG:ronan:running training loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time  epoch       iteration   main/accuracy  validation/main/accuracy  main/loss   validation/main/loss\n",
      "\u001b[J2.84821       0           1           0.445312                                 1.29162                           \n",
      "\u001b[J8.74846       0           2           0.460938       0.519531                  42.6041     6.40491               \n",
      "\u001b[J16.9611       0           3           0.484375                                 10.0078                           \n",
      "\u001b[J22.4576       0           4           0.5            0.527344                  6.45082     20.5789               \n",
      "\u001b[J24.5136       0           5           0.484375                                 19.5313                           \n",
      "\u001b[J30.0429       0           6           0.515625       0.511719                  13.4144     7.7957                \n",
      "\u001b[J32.1384       0           7           0.570312                                 8.45793                           \n",
      "\u001b[J37.6568       0           8           0.476562       0.632812                  13.9016     3.79613               \n",
      "\u001b[J45.8965       0           9           0.492188                                 6.18131                           \n",
      "\u001b[J51.3919       0           10          0.515625       0.5625                    12.1351     11.211                \n",
      "\u001b[J53.4574       0           11          0.492188                                 14.4976                           \n",
      "\u001b[J59.0151       0           12          0.570312       0.46875                   4.46517     11.6581               \n",
      "\u001b[J61.0895       0           13          0.515625                                 11.4667                           \n"
     ]
    }
   ],
   "source": [
    "base = ronan.ResNet50Features(output_layer='res5', finetune_from_layer='res1')\n",
    "net = ronan.DualNet(base, output_size=2)\n",
    "ronan.train(net, data_1M, '1M-ores5-fres1',\n",
    "            train_batch_size=128,\n",
    "            validation_batch_size=256,\n",
    "            trigger_save_trainer=(500, 'iteration'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:ronan:setting up optimizer\n",
      "DEBUG:ronan:creating trainer\n",
      "INFO:ronan:full model name: DualNet-1M-ores5-fres1-batch128\n",
      "DEBUG:ronan:running training loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time  epoch       iteration   main/accuracy  validation/main/accuracy  main/loss   validation/main/loss\n",
      "\u001b[J2.93532       0           1           0.460938                                 1.37283                           \n",
      "\u001b[J8.63034       0           2           0.492188       0.496094                  4818.55     3407.54               \n",
      "\u001b[J17.0315       0           3           0.5                                      3238.39                           \n",
      "\u001b[J22.4847       0           4           0.515625       0.527344                  2074.39     2181.14               \n",
      "\u001b[J30.6957       0           5           0.523438                                 2209.65                           \n",
      "\u001b[J36.1547       0           6           0.453125       0.5                       1670.83     2438.79               \n",
      "\u001b[J38.1997       0           7           0.578125                                 1993.8                            \n",
      "\u001b[J43.6627       0           8           0.476562       0.464844                  565.966     2014.02               \n",
      "\u001b[J51.8392       0           9           0.414062                                 2103.71                           \n",
      "\u001b[J57.3295       0           10          0.484375       0.570312                  1592.18     1065.28               \n",
      "\u001b[J65.5524       0           11          0.601562                                 952.604                           \n",
      "\u001b[J71.0542       0           12          0.546875       0.542969                  731.874     1151.84               \n",
      "\u001b[J73.1306       0           13          0.515625                                 1245.87                           \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d4f6694c4985>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             trigger_save_trainer=(500, 'iteration'))\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/projects/fastai/courses/deeplearning1/nbs/ronan.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(predictor, data, name, train_batch_size, validation_batch_size, trigger_save_trainer, optimizer, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'running training loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/training/trainer.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, show_loop_exception_msg)\u001b[0m\n\u001b[1;32m    300\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                             \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshow_loop_exception_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/training/extensions/evaluator.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mreporter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mconfiguration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musing_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mreporter_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/projects/fastai/courses/deeplearning1/nbs/ronan.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_backprop_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m                     \u001b[0meval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                     \u001b[0meval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/links/model/classifier.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlossfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mreporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/projects/fastai/courses/deeplearning1/nbs/ronan.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mi2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         h = chainer.functions.concat((self.base(i1),\n\u001b[0;32m--> 102\u001b[0;31m                                       self.base(i2)))\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_final\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/projects/fastai/courses/deeplearning1/nbs/ronan.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m         return call_finetune(x, self.resnet50,\n\u001b[1;32m     83\u001b[0m                              \u001b[0mbackprop_from_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinetune_from_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                              target_layer=self.output_layer)\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/projects/fastai/courses/deeplearning1/nbs/ronan.py\u001b[0m in \u001b[0;36mcall_finetune\u001b[0;34m(x, net, backprop_from_layer, target_layer)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmaybe_backprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget_layer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/links/model/vision/resnet.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/chainer/links/model/vision/resnet.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base = ronan.ResNet50Features(output_layer='res5', finetune_from_layer='res1')\n",
    "net = ronan.DualNet(base, output_size=2)\n",
    "ronan.train(net, data_1M, '1M-ores5-fres1-rmsprop',\n",
    "            train_batch_size=128,\n",
    "            validation_batch_size=256,\n",
    "            optimizer=chainer.optimizers.RMSprop(),\n",
    "            trigger_save_trainer=(500, 'iteration'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
